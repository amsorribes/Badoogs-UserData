{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the list of dog races: Manually copy from item inspect, save to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "readfile = '..\\\\data\\\\races\\\\races_tags.txt'\n",
    "writefile = '..\\\\data\\\\races\\\\dog_races.txt'\n",
    "\n",
    "# Read file \n",
    "with open(readfile, 'r') as rf:\n",
    "    data = rf.read().split('</option>')\n",
    "data = data[:-1]\n",
    "\n",
    "# Extract list of races\n",
    "races = [s.split('>')[1] for s in data]\n",
    "\n",
    "# Write list of races\n",
    "with open(writefile, 'w') as wf:\n",
    "    wf.write('\\n'.join(races))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Scrape Dog Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spanish_Spain.1252'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import locale\n",
    "locale.setlocale(locale.LC_TIME, 'esn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions to retreive information from each dog entry\n",
    "def get_photo(entry_soup):\n",
    "    ''' \n",
    "    Return url (string) of photo for entry \n",
    "    '''\n",
    "    div_photo = entry_soup.find_all('div', attrs={'class':'ficha-mascota-foto'})\n",
    "    url_photo = div_photo[0].find('img')['src']\n",
    "    if url_photo == \"/img/common/usuarios-nofoto.gif\":\n",
    "        url_photo = ''\n",
    "    return url_photo\n",
    "\n",
    "def get_entry(entry_soup):\n",
    "    '''\n",
    "    Return list of fields from entry\n",
    "    '''    \n",
    "    soup = entry_soup.find_all('div', attrs={'class':'ficha-mascota-info'})\n",
    "    fields = []\n",
    "    try:\n",
    "        for b in soup[0].find_all('b'):\n",
    "            fields.append(b.get_text().strip())\n",
    "    except:\n",
    "        fields = []\n",
    "    return fields\n",
    "\n",
    "def get_owner(entry_soup):\n",
    "    ''' \n",
    "    Returns string of owner name\n",
    "    '''\n",
    "    user_soup = entry_soup.find_all('div', attrs={'id':'info-user-int'})\n",
    "    temp = user_soup[0].find_all('h4')\n",
    "    return temp[0].get_text()\n",
    "    \n",
    "\n",
    "def make_dbdict(url_photo, entry_field, entry_owner, ped):\n",
    "    # Transformations and integrity control\n",
    "    if entry_field[5].capitalize() not in {'Hembra', 'Macho'}:\n",
    "        entry_field[5] = ''\n",
    "    dtobj = datetime.strptime(entry_field[2], '%d de %B de %Y')\n",
    "    \n",
    "    db_dict = {'name': entry_field[0], \\\n",
    "               'gender': entry_field[5], \\\n",
    "               'city': entry_field[-1], \\\n",
    "               'photo': url_photo, \\\n",
    "               'pedigree': ped, \\\n",
    "               'race': entry_field[1], \\\n",
    "               'born':{'__type': \"Date\", 'iso': dtobj.strftime('%Y-%m-%dT00:00:00.000Z')}, \\\n",
    "               'username': entry_owner, \\\n",
    "               'useremail': entry_owner + '@traitydogs.com', \\\n",
    "              }\n",
    "#               'location': [], \\\n",
    "    return db_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "29\n",
      "43\n",
      "59\n",
      "71\n",
      "85\n",
      "97\n",
      "110\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "url_base = 'http://www.perros.com'\n",
    "entry_dicts = []\n",
    "\n",
    "# Loop over all search gallery pages\n",
    "#range(1,1317+1)\n",
    "for ipage in range(2,10):\n",
    "    url_gallery = \"http://www.perros.com/nuestros-perros/%d/?sexo=&raza=&pais=8&provincia=&localidad=\" % ipage\n",
    "\n",
    "    # Get links to each dog from the current search gallery page\n",
    "    gallery_soup = bs4.BeautifulSoup(requests.get(url_gallery).text)\n",
    "    gallery_links = []\n",
    "    for div in gallery_soup.find_all('div', attrs={'class':'buscador-item'}):\n",
    "        gallery_links.append(div.a['href'])\n",
    "\n",
    "    # Get Pedigree for each dog in gallery\n",
    "    gallery_str = str(gallery_soup.find_all('div', attrs={'class':'buscador-item'}))\n",
    "    findstr = '<b>Pedigree:</b> '\n",
    "    pedigree = [gallery_str[i+len(findstr):i+len(findstr)+2] for i in [s.start() for s in re.finditer(findstr, gallery_str)]]\n",
    "    pedigree = [s == 'Si' for s in pedigree]\n",
    "\n",
    "    # Check that pedigree is equal in size to gallery_links list\n",
    "    if len(gallery_links) != len(pedigree):\n",
    "        print('Some dog at page %d does not have pedigree' % ipage)\n",
    "\n",
    "    # For each Dog Entry    \n",
    "    for entry_link, ped in zip(gallery_links, pedigree):\n",
    "        response = requests.get(url_base + entry_link)    \n",
    "        if response.status_code != 404:\n",
    "            entry_soup = bs4.BeautifulSoup(response.text)\n",
    "            url_photo = get_photo(entry_soup)\n",
    "            if url_photo:\n",
    "                entry_field = get_entry(entry_soup)\n",
    "                entry_owner = get_owner(entry_soup)\n",
    "                db_dict = make_dbdict(url_base + url_photo, entry_field, entry_owner, ped)\n",
    "                entry_dicts.append(db_dict)\n",
    "    print(len(entry_dicts))\n",
    "\n",
    "\n",
    "with open('Dog.json', 'w') as fdb:\n",
    "    fdb.write('{ \"results\": ')\n",
    "    fdb.write(json.dumps(entry_dicts, sort_keys=True, indent=4))\n",
    "    fdb.write(' }')\n",
    "print('Success!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div id=\"info-user-int\">\n",
      "<a href=\"/usuarios/silf.html\"><img align=\"middle\" alt=\"Sin foto\" height=\"58\" src=\"/img/common/usuarios-nofoto.gif\" width=\"58\"/></a>\n",
      "<h4><a href=\"/usuarios/silf.html\">Silf</a></h4>\n",
      "\t\t\t\t\tVilamarxant (Valencia) <br/>\n",
      "<b>Sexo:</b> Mujer\t\t\t\t\t<div class=\"foro-ver-usuario\">\n",
      "<a class=\"fotos\" href=\"/usuarios/silf.html\">0  Albums</a> Â  <a class=\"huella\" href=\"/usuarios/silf.html\">2 perros</a>\n",
      "</div>\n",
      "</div>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(entry_soup.find_all('div', attrs={'id':'info-user-int'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Silf'"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = user_soup[0].find_all('h4')\n",
    "temp[0].get_text()\n",
    "#.get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
